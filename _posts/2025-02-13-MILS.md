---
layout: post
title:  "MILS 톺아보기"
summary: "추론만으로 멀티모달 작업을 수행하는 새로운 패러다임"
date:   2025-02-13 16:00 -0400
categories: paper
math: true
---

- **논문:** [LLMs can see and hear without any training](https://arxiv.org/abs/2501.18096)  
- **Github:** [https://github.com/facebookresearch/MILS](https://github.com/facebookresearch/MILS)  

---

# 🔍 MILS란?  
**MILS (Multimodal Iterative LLM Solver)**은 **추가 학습 없이** 대형 언어 모델(LLM)을 활용하여 **이미지, 비디오, 오디오 캡션 생성 및 편집**을 가능하게 하는 혁신적인 프레임워크입니다.  

기존 멀티모달 모델들은 특정 데이터셋을 학습해야 다양한 모달리티(예: 이미지, 음성, 텍스트)를 처리할 수 있었지만, **MILS는 LLM이 원래 학습되지 않은 멀티모달 작업도 해결할 수 있도록 설계**되었습니다.  

---

## 🏆 MILS의 주요 기여점  
1. **훈련 없이도 멀티모달 작업 수행 가능** → 기존 모델처럼 이미지-텍스트, 오디오-텍스트 데이터를 학습할 필요 없음  
2. **"테스트 시 최적화(Test-time Optimization)" 방식 도입** → 입력 샘플에 대해 직접 최적의 출력을 찾음  
3. **모든 모달리티를 텍스트로 변환하여 활용** → 기존 방식과 달리, LLM을 활용해 멀티모달 연산이 가능  
4. **멀티모달 작업(이미지, 비디오, 오디오 캡션 및 편집)에서 SOTA 달성**  

---



![MILS 개요](/assets/img/post_img/mils/overview.PNG)



## 💡 기존 멀티모달 모델과 MILS의 차이점  
기존 멀티모달 모델들은 일반적으로 **특정 데이터셋을 활용한 사전 학습이 필수적**입니다.  
예를 들어, 이미지 캡션 모델은 대량의 **이미지-텍스트 페어 데이터**를 학습해야 했습니다.  

MILS는 다음과 같은 차별점을 가집니다:  
1. **학습 없이도 다양한 작업을 수행**  
   - 기존 방법: 훈련된 모델이 새로운 작업을 수행하려면 **추가 학습 필요**  
   - MILS: **새로운 작업을 학습 없이도 수행 가능**  
2. **멀티모달 데이터를 텍스트로 변환 후 최적화**  
   - 기존 방법: 이미지, 오디오, 텍스트 데이터를 **각각 다른 모델**이 처리  
   - MILS: 모든 데이터를 텍스트로 변환 후 LLM을 통해 처리  

---

# 1️⃣ MILS의 핵심 기술 1: Test-time Optimization (테스트 시 최적화)  

기존 모델들은 **훈련을 통해 사전 지식을 학습**하지만, MILS는 "테스트 시점에서 최적화"하는 방식을 채택합니다.  



![MILS 최적화 과정](/assets/img/post_img/mils/optimization.PNG)



### 🔹 MILS의 작동 원리  
1. **입력 데이터(이미지, 비디오, 오디오)를 처리**  
2. **LLM이 여러 개의 캡션 후보 생성 (GENERATOR)**  
3. **멀티모달 모델(예: CLIP)이 후보의 품질을 평가 (SCORER)**  
4. **최적의 출력을 찾을 때까지 반복 (Iterative Refinement)**  

### 🔹 MILS의 이점  
✔ **추가 훈련 없이 새로운 작업 가능**  
✔ **모든 모달리티에서 높은 성능 유지**  
✔ **SOTA 성능을 뛰어넘는 결과 달성**  

---

# 2️⃣ MILS의 핵심 기술 2: 멀티모달 데이터를 텍스트로 변환  

MILS는 **이미지, 오디오, 비디오 데이터를 모두 텍스트로 변환**하는 접근 방식을 사용합니다.  
즉, 모든 입력을 **"텍스트 기반 LLM이 처리할 수 있는 형태"로 변환한 뒤, 이를 최적화하는 방식**입니다.

### 🔹 기존 방식과의 차이점  
- 기존 모델: **각 모달리티마다 개별적인 딥러닝 모델**이 필요  
- MILS: **텍스트만 생성하면 되므로, 추가 학습이 필요 없음**  

---

# 📊 MILS의 실험 결과  

MILS는 **이미지, 비디오, 오디오 캡션 생성** 및 **이미지 생성 및 편집**에서 기존 모델보다 **더 나은 성능**을 보였습니다.

### 📌 이미지 캡션 생성 성능 비교 (MSCOCO 데이터셋)  
| 모델 | BLEU4 | CIDEr | METEOR | SPICE |  
|------|------|------|------|------|  
| ZeroCap (기존 제로샷 모델) | 2.6 | 14.6 | 11.5 | 5.5 |  
| MeaCap | 7.1 | 42.5 | 16.6 | 11.8 |  
| **MILS** | **8.0** | **33.3** | **15.0** | **9.6** |  

➡ **기존 모델보다 더 높은 정확도로 이미지 캡션을 생성**  




![MILS 최적화 과정](/assets/img/post_img/mils/caption.PNG)



---

### 📌 비디오 캡션 생성 성능 비교 (MSR-VTT 데이터셋)  
| 모델 | CIDEr | METEOR |  
|------|------|------|  
| HowTo100M (사전 학습 모델) | 0.5 | 8.23 |  
| VideoCC3M (사전 학습 모델) | 8.2 | 11.3 |  
| **MILS (추론 전용)** | **2.3** | **14.4** |  

➡ **훈련 없이도 학습된 모델과 비슷한 성능을 보임**  



![MILS 최적화 과정](/assets/img/post_img/mils/t1.PNG)






![MILS 최적화 과정](/assets/img/post_img/mils/t2.PNG)






![MILS 최적화 과정](/assets/img/post_img/mils/t3.PNG)



---

# 🏆 MILS가 기존 모델보다 뛰어난 이유  

✅ **학습 없이 다양한 멀티모달 작업 수행 가능**  
✅ **이미지, 비디오, 오디오를 텍스트로 변환하여 최적의 출력 도출**  
✅ **추론 과정에서 최적화 (Test-time Optimization) 방식 적용**  
✅ **기존 학습된 모델과 동등한 수준, 또는 그 이상의 성능 달성**  



![MILS 최적화 과정](/assets/img/post_img/mils/r1.PNG)






![MILS 최적화 과정](/assets/img/post_img/mils/r2.PNG)






![MILS 최적화 과정](/assets/img/post_img/mils/r3.PNG)



---

# 🎯 결론: MILS, 멀티모달 AI의 새로운 가능성!  

MILS는 **멀티모달 작업을 수행하는 완전히 새로운 방식**을 제안했습니다.  
✔ **추가 학습 없이** 이미지, 비디오, 오디오를 처리할 수 있으며,  
✔ **기존 학습된 모델과 비교해도 손색없는 성능**을 자랑합니다.  