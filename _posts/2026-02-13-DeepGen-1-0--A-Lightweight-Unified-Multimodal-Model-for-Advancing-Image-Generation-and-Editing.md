---
layout: post
title: '[2026-02-12] DeepGen 1.0: 5B 파라미터로 80B를 압도하는 경량 통합 멀티모달 모델의 혁신'
date: '2026-02-13'
categories: tech
math: true
summary: 5B 규모로 80B 성능을 뛰어넘는 차세대 이미지 생성 및 편집 모델 DeepGen 1.0 분석
image:
  path: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12205.png
  alt: Paper Thumbnail
---

## 핵심 요약 (Executive Summary)

인공지능 연구의 흐름은 그동안 '거거익선(Bigger is Better)'이라는 명제 아래 파라미터 수를 기하급수적으로 늘리는 방향으로 진행되어 왔습니다. 그러나 최근 발표된 **DeepGen 1.0**은 이러한 흐름에 정면으로 도전하며, 단 **5B(50억 개) 파라미터**만으로도 80B 규모의 거대 모델인 HunyuanImage를 압도하는 성능을 증명했습니다. 

DeepGen 1.0은 이미지 생성(Generation)과 편집(Editing)을 하나의 프레임워크 내에서 통합한 **경량 통합 멀티모달 모델(Lightweight Unified Multimodal Model)**입니다. 이 모델의 핵심 혁신은 세 가지로 요약됩니다: 
1. **Stacked Channel Bridging (SCB)**: VLM의 계층적 특징을 추출하여 생성 백본에 구조적 추론 가이드를 제공하는 딥 얼라이먼트 프레임워크.
2. **데이터 중심 3단계 학습 전략**: 정렬 프리트레이닝, 통합 SFT, 그리고 강화학습(RL)을 결합한 정교한 파이프라인.
3. **MR-GRPO**: DeepSeek-V3 등에서 영감을 얻은 GRPO 알고리즘을 이미지 도메인에 최적화하여 보상 함수 혼합을 통해 생성 품질을 극대화한 기술.

본 분석 보고서에서는 DeepGen 1.0이 어떻게 효율성과 성능이라는 두 마리 토끼를 잡았는지, 그리고 이 기술이 향후 생성 AI 생태계에 어떤 파급력을 미칠지 심층적으로 분석합니다.

---

## 1. 연구 배경 및 문제 정의 (Introduction & Problem Statement)

### 거대 모델의 역설: 비용과 배포의 한계
현재 통합 멀티모달 모델(Unified Multimodal Models) 시장은 성능을 위해 효율성을 희생하고 있습니다. Sora, HunyuanImage, Flux와 같은 모델들은 뛰어난 결과물을 보여주지만, 최소 10B에서 최대 80B 이상의 파라미터를 요구합니다. 이는 다음과 같은 치명적인 문제를 야기합니다:
- **천문학적인 학습 비용**: 수천 장의 H100 GPU를 수개월간 가동해야 하는 인프라 장벽.
- **실시간 배포의 어려움**: 에지 컴퓨팅이나 일반 소비자용 디바이스에서 실행하기 불가능한 메모리 풋프린트.
- **데이터 효율성 저하**: 모델이 커질수록 이를 채우기 위한 고품질 데이터의 요구량도 기하급수적으로 늘어납니다.

### DeepGen 1.0의 도전: '작지만 강력한' 모델
DeepGen 연구팀은 "왜 모델이 커야만 하는가?"라는 질문에서 시작했습니다. 기존의 경량 모델들은 의미론적 이해(Semantic Understanding)와 미세 제어(Fine-grained Control)에서 한계를 보였습니다. DeepGen 1.0은 **구조적 정렬(Structural Alignment)**과 **추론 기반 가이딩(Reasoning-rich Guidance)**을 통해 5B라는 컴팩트한 사이즈에서도 거대 모델 이상의 복잡한 명령 수행 능력을 갖추도록 설계되었습니다.

---

## 2. 핵심 기술 및 아키텍처 심층 분석 (Core Methodology)

DeepGen 1.0의 아키텍처는 단순한 결합이 아닌, VLM(Vision-Language Model)과 DiT(Diffusion Transformer) 간의 유기적 융합에 초점을 맞추고 있습니다.

### 2.1 Stacked Channel Bridging (SCB): 계층적 의미 추출의 마법
기존 모델들은 VLM의 마지막 레이어 출력물만을 텍스트 임베딩으로 사용합니다. 하지만 마지막 레이어는 고도의 추상적 의미만 담고 있어, 생성에 필요한 구체적인 레이아웃이나 질감 정보를 놓치기 쉽습니다.

SCB는 VLM의 **멀티 레이어(Multiple Layers)**에서 계층적 특징을 추출합니다. 
- **Lower Layers**: 기계적인 형태, 색상, 텍스트 배치 정보를 제공.
- **Higher Layers**: 전체적인 분위기, 논리적 관계, 복잡한 추론 정보를 제공.

이러한 정보들은 연구팀이 도입한 **'Think Tokens'**와 융합됩니다. Think Token은 모델이 이미지를 그리기 전, 내부적으로 '어떻게 구성할 것인가'에 대한 잠재적인 사고 과정을 수행하도록 유도하는 학습 가능한 매개변수입니다. 이는 마치 숙련된 화자가 말을 하기 전 머릿속으로 문장을 구성하는 것과 유사한 원리입니다.

### 2.2 MR-GRPO: 이미지 생성을 위한 강화학습의 진화
DeepGen 1.0의 가장 독창적인 부분 중 하나는 **MR-GRPO (Mixture of Reward Group Relative Policy Optimization)**입니다. 

최근 DeepSeek의 R1 모델로 유명해진 GRPO는 별도의 비평가(Critic) 모델 없이 그룹 내 상대적 보상을 통해 학습 효율을 높이는 방식입니다. 연구팀은 이를 이미지 도메인으로 확장했습니다.
- **보상 함수의 혼합(Mixture of Rewards)**: 단순히 '예쁜 이미지'를 만드는 것이 아니라, 텍스트 정렬도(CLIP Score), 미적 가치(Aesthetic Score), 그리고 인간 선호도 정보를 모두 결합한 다면적 보상을 제공합니다.
- **Artifact 방지**: 강화학습 과정에서 흔히 발생하는 '보상 해킹(Reward Hacking)' 현상으로 인한 시각적 아티팩트(깨짐 현상)를 방지하기 위해 안정적인 정책 업데이트 매커니즘을 적용했습니다.

### 2.3 3단계 학습 전략 (Three-stage Training)
1. **Stage 1: Alignment Pre-training**: 약 5,000만 개의 이미지-텍스트 쌍을 통해 VLM과 DiT 사이의 언어를 맞추는 단계입니다. 특히 편집(Editing) 성능을 위해 비포/애프터 이미지 트리플레이트 데이터를 활용하여 변화의 맥락을 학습시킵니다.
2. **Stage 2: Joint SFT**: 생성, 편집, 그리고 시각적 추론 작업이 혼합된 고품질 데이터셋으로 미세 조정을 진행합니다. 이를 통해 모델은 단순한 생성을 넘어 '명령의 의도'를 파악하는 능력을 갖추게 됩니다.
3. **Stage 3: RL with MR-GRPO**: 최종적으로 인간의 피드백과 정렬하여 결과물의 디테일과 선호도를 극대화합니다.

---

## 3. 구현 및 실험 환경 (Implementation Details)

### 데이터셋 및 컴퓨팅 자원
DeepGen 1.0은 놀랍게도 단 **50M(5천만 개)**의 샘플만으로 학습되었습니다. 이는 수십 억 개의 데이터를 사용하는 경쟁 모델들에 비해 매우 적은 양입니다. 이는 데이터의 '양'보다 '질'과 '학습 전략'이 얼마나 중요한지를 시사합니다.
- **Backbone**: Llama-3 기반의 VLM과 최적화된 DiT 블록 사용.
- **Precision**: BF16 혼합 정밀도 학습을 통해 효율성 확보.
- **Infrastructure**: A100/H100 클러스터에서 수행되었으나, 모델 사이즈가 작아 학습 시간은 수 분의 일로 단축되었습니다.

---

## 4. 성능 평가 및 비교 (Comparative Analysis)

DeepGen 1.0은 벤치마크 테스트에서 체급을 뛰어넘는 '자이언트 킬링'을 보여주었습니다.

### 4.1 이미지 생성 성능 (WISE Benchmark)
- **DeepGen 1.0 (5B)**: WISE 벤치마크에서 **HunyuanImage (80B)** 대비 **28% 높은 성능** 기록.
- 복잡한 텍스트 렌더링 및 다중 객체 배치에서 압도적인 정확도를 보였습니다. 이는 SCB가 제공하는 구조적 정보 덕분인 것으로 분석됩니다.

### 4.2 이미지 편집 성능 (UniREditBench)
- **DeepGen 1.0 (5B)**: **Qwen-Image-Edit (27B)** 대비 **37% 성능 우위** 점유.
- 단순히 이미지를 바꾸는 것이 아니라, 원본의 특징을 유지하면서 명령에 따른 부분적인 수정을 수행하는 능력에서 탁월한 일관성(Consistency)을 보여주었습니다.

### 4.3 효율성 지표
- 모델 크기: 80B 대비 **1/16 수준**.
- 추론 속도: 단일 소비자용 GPU(RTX 4090 등)에서 원활한 구동 가능.

---

## 5. 실제 적용 분야 및 글로벌 파급력 (Real-World Application)

DeepGen 1.0의 등장은 기술적 진보를 넘어 산업 전반에 큰 변화를 예고합니다.

### 5.1 온디바이스 AI 및 모바일 크리에이티비티
5B 파라미터는 모바일 칩셋이나 고성능 노트북에서 실시간으로 구동 가능한 임계점입니다. 사용자는 클라우드 서버에 이미지를 업로드할 필요 없이, 자신의 기기 내에서 즉각적으로 고품질 이미지를 생성하고 정교하게 편집할 수 있습니다. 이는 개인 정보 보호와 실시간성이라는 두 마리 토끼를 잡는 결과로 이어집니다.

### 5.2 이커머스 및 마케팅 자동화
쇼핑몰 운영자는 모델 사진의 의상만 바꾸거나, 배경을 시즌에 맞춰 변경하는 등의 작업을 전문 디자이너 없이도 수행할 수 있습니다. DeepGen 1.0의 정교한 편집 능력은 제품의 본질은 유지하면서도 분위기만 바꾸는 '상업적 편집'에 최적화되어 있습니다.

### 5.3 연구 및 개발의 민주화
연구팀은 코드와 가중치(Weights)를 오픈소스로 공개했습니다. 이는 대규모 자본을 가진 빅테크 기업만이 점유하던 고성능 멀티모달 연구를 일반 개발자와 소규모 스타트업에게 개방하는 효과를 낳습니다. 이른바 '생성 AI의 민주화'가 가속화될 것입니다.

---

## 6. 기술적 비평 및 한계점 (Discussion & Critique)

Senior Chief AI Scientist로서 이 모델의 성과를 높이 평가하지만, 몇 가지 비판적 시각도 존재합니다.

### 6.1 데이터 다양성의 한계
50M 샘플은 고품질일 수 있으나, 전 세계의 다양한 문화적 맥락이나 매우 희귀한 엣지 케이스(Edge Cases)를 모두 커버하기에는 부족할 수 있습니다. 특정 스타일이나 구도에 편향(Bias)이 생길 가능성을 배제할 수 없습니다.

### 6.2 RLHF의 부작용 (Reward Hacking)
MR-GRPO가 시각적 아티팩트를 방지한다고 주장하지만, 강화학습 기반의 생성 모델은 종종 '지나치게 선명한' 혹은 '비현실적으로 화려한' 이미지를 만드는 경향이 있습니다. 이는 미적 점수(Aesthetic Score)를 높이기 위한 모델의 편법일 수 있으며, 실제 사진 같은 자연스러움을 해칠 위험이 있습니다.

### 6.3 SCB의 연산 오버헤드
VLM의 여러 레이어에서 특징을 추출하는 SCB 방식은 단일 레이어 방식보다 당연히 연산 비용이 큽니다. 비록 5B 규모라 하더라도, 추론 시의 메모리 대역폭 활용 효율성을 극대화하기 위한 추가적인 최적화(Quantization 등) 연구가 병행되어야 할 것입니다.

---

## 7. 결론 및 인사이트 (Conclusion)

DeepGen 1.0은 "모델의 지능은 파라미터 수에만 비례하지 않는다"는 것을 여실히 보여준 사례입니다. 정교한 아키텍처 설계(SCB)와 혁신적인 학습 알고리즘(MR-GRPO)이 결합되었을 때, 10배 이상 큰 모델을 이길 수 있다는 사실은 AI 업계에 신선한 충격을 주고 있습니다.

이제 시장의 관심은 무조건적인 확장(Scaling)에서 **'밀도 높은 지능(Dense Intelligence)'**으로 옮겨갈 것입니다. DeepGen 1.0은 그 변곡점에 서 있는 모델이며, 앞으로의 생성 AI는 더 작고, 더 빠르며, 더 똑똑해지는 방향으로 진화할 것입니다.

기술의 민주화를 꿈꾸는 오픈소스 커뮤니티와 효율적인 AI 솔루션을 찾는 기업들에게 DeepGen 1.0은 가장 강력한 무기가 될 것입니다. 우리도 이제 '크기'의 함정에서 벗어나 '구조'와 '데이터'의 본질에 집중해야 할 때입니다.

---

*본 칼럼은 DeepGen 1.0 기술 논문을 바탕으로 작성되었으며, 필자의 주관적인 기술 분석이 포함되어 있습니다.*

[Original Paper Link](https://huggingface.co/papers/2602.12205)