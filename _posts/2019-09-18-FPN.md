---
layout: post
title:  "FPN 톺아보기"
summary: "FPN 논문 읽어보기"
date:   2019-09-18 13:00 -0400
categories: paper
math: true
---

## FPN

(**Feature Pyramid Networks**)

- FPN Paper : [Here](https://arxiv.org/abs/1612.03144)

Object Detection 분야에 많이 적용되고 있는 Network

## Abstract
feature pyramid는 다양한 스케일로 object detection 하기 위한 인식 시스템의 기본 구성 요소다. 하지만 object detector들은 pyramid로 표현하는 것을 피했다. 왜냐하면 부분적으로 계산하고 메모리가 집약적이기 때문이다. 이 논문에서는 **pyramid 계층 구조를 활용해서 낮은 비용으로 feature pyramid를 구성** 한다.


## Introduction



![figure1](/assets/img/post_img/fpn/figure1.PNG)



##### a) 이미지를 pyramid로 만들어 사용하여 feature pyramid 만들기
서로 다른 스케일로 물체를 인식하는 해결방법의 기초다. 이러한 속성을 사용하면 광범위한 범위에서 객체를 감지할 수 있다. 하지만 각 이미지 스케일에서 독립적으로 계산되므로 느리다.


##### b) 단일 스케일만 사용하도록 선택하는 방법
feature를 압축하는 방식이다. 하지만 pyramid를 사용하지 않고 압축시킨 feature만 사용하기 때문에 성능이 떨어진다. 그래서 이미지 pyramid 구조가 필요하지만 각 level을 특징짓는 것은 시간이 상당히 증가하기 때문에 실용적이지 않다.


##### c) convolution network로 계산된 feature pyramid 계층을 마치 특징화된 이미지 pyramid 인 것처럼 다시 사용하는 방법


##### d) **FPN** (b)와 (c)와 같이 빠르지만 강력하다.
이 논문의 목표는 모든 규모에서 강한 feature pyramid를 만드는 것이다. 이 목표를 달성 하기 위해서 하향식 경로와 측면 연결을 통해 저해상도의 강력한 feature와 고해상도의 약한 feature를 결합한 구조를 사용한다.

- 검출율 : `Average Recall(AR)` : 8.0 point (ex. 전체 암이 있는 사람 중 정확히 암진단을 받은 경우)
- 정확도 : `COCO Average Precision(AP)` : 2.3 point , `PASCAL Average Precision(AP)` : 3.8 point (ex. 암진단 받은 사람 중 정확히 암진단을 받은 경우)
- 시간이 늘어나지 않으면서 좋은 정확도를 가진다.



![figure2](/assets/img/post_img/fpn/figure2.PNG)



## Feature Pyramid Networks



![figure3](/assets/img/post_img/fpn/figure3.PNG)



FPN의 목표는 낮은 수준에서 높은 수준으로 의미가 있는 convolution network로 계산된 feature pyramid 계층 구조를 활용해서 고성능 pyramid를 만드는 것이다.

### Bottom-up pathway
- 상향식 경로는 convolution network의 계산으로 여러 스케일의 feature map으로 구성된 feature 계층을 계산하고 스케일은 2배씩 증가한다.

- feature pyramid의 경우 각 단계마다 하나의 pyramid level을 정의한다. 그리고 각 단계의 마지막 layer의 출력을 참조시킨다.

- resnet에서는 마지막 residual block에서의 출력을 참조하며 메모리 공간 때문에 pyramid에 conv1을 포함시키지 않는다.

### Top-down pathway and lateral connections
- 측면 연결은 상향식 경로와 하향식 경로에서 동일한 크기의 feature map을 병합한다.

- 하향식 경로에서 2배로 업 샘플링을 하고 해당 상향식 경로의 feature map과 병합한다. 채널의 크기를 줄이기 위해서 1x1 convolution layer를 거친다. 마지막으로 업 샘플링의 앨리어싱 효과를 줄이는 최종 feature map을 생성하기 위해서 3x3 convolution을 추가한다.

- pyramid의 모든 level은 공유되는 classifiers와 regressors를 사용하기 때문에 feature의 차원을 256으로 설정한다.

## Applications



![figure](/assets/img/post_img/fpn/figure.PNG)



출처 : [https://medium.com/@jonathan_hui/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c](https://medium.com/@jonathan_hui/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c)

이 논문에서는 Faster R-CNN에 FPN을 적용한다.

### Feature Pyramid Networks for RPN
- `RPN`은 원래 3x3 슬라이딩 윈도우에서 평가되어 오브젝트인지 아닌지 이진 분류하고 bounding box 회귀를 수행한다. 이것은 3x3 convolution layer와 분류/회귀를 위한 2개의 1x1 convolution으로 실현되고 이것을 network head라고 한다.

- `anchor`는 다양한 모양의 객체를 덮기 위해 미리 정의 된 여러 배율과 종횡비다.

- 단일 스케일 feature map을 FPN으로 대체하여 RPN을 조정하면 feature pyramid의 각 level에 동일한 network head를 추가한다. 그리고 anchor를 각 level에 할당한다.({$$32^2,64^2,128^2,256^2,512^2$$}) 그리고 다중 종횡비 {$$1:2, 1:1, 2:1$$}을 각각 추가해서 총 15개의 anchor를 사용한다.

- IOU 비율을 기준으로 anchor에 training labels를 할당한다. 공식적으로 anchor는 IOU가 0.7 이상이면 양수 0.3보다 낮으면 음수로 지정된다.

### Feature Pyramid Networks for Fast R-CNN
- `Fast R-CNN`은 ROI pooling을 사용하여 feature를 추출하는 영역 기반 object detector다. 그래서 FPN에 적용하기 위해서는 ROI를 $$Pk$$에 할당해야한다.


$$k = k_0 + \log_2(\sqrt{wh}/224)$$


- $$P_k$$ : pyramid level
- $$w,h$$ : ROI의 width,height
- $$224$$ : ImageNet pretraing size
- $$k_0$$ : ROI가 매핑되어야 하는 목표 level(4로 설정)

여기서 직관적으로 예를 들어 ROI의 스케일이 줄어들면(224의 1/2) 해상도 level은 k=3에 매핑되어야한다.

### Benchmark



![bench1](/assets/img/post_img/fpn/benchmark.PNG)






![bench2](/assets/img/post_img/fpn/benchmark2.PNG)



## Concept
읽으면서 찾아본 개념

### ROI pooling
Fast R-CNN에 적용되는 개념으로 Fast R-CNN은 two-stage object detector다. pretraing된 모델로 feature map을 추출한뒤 RPN(Region proposal network)으로 분기가 나누어 진다. 그리고 RPN에서 추출된 제안된 영역과 feature map을 합친다. 이 합쳐지는 과정에서 각각의 제안된 영역의 크기가 각각 다르기 때문에 ROI pooling을 사용한다.

1. 각각의 제안된 영역을 동일한 크기의 section으로 나눈다.
2. 각 section마다 최대값을 찾아서 반환한다.


#### 학습

- RPN으로 부터 얻은 제안된 영역(anchor), ground truth box : `cross entropy loss`
- 예측 box 좌표, 실제 box 좌표 : `smooth L1 loss`

#### 추론

**RPN**
- classification : object 인가 아닌가?(IOU)
- regression : x,y,w,h 값을 구하고 anchor에 적용시켜 최종 proposal을 얻는다.

**ROI**
- classification : 어떤 object 인가??
- regression : bounding box의 좌표를 조정한다.

## Reference
- AR/AP : [https://smwgood.tistory.com/17](https://smwgood.tistory.com/17)
- Fast R-CNN : [https://incredible.ai/deep-learning/2018/03/17/Faster-R-CNN/](https://incredible.ai/deep-learning/2018/03/17/Faster-R-CNN/)
- Fast R-CNN code : [https://github.com/longcw/faster_rcnn_pytorch](https://github.com/longcw/faster_rcnn_pytorch)
- 그림 : [https://medium.com/@jonathan_hui/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c](https://medium.com/@jonathan_hui/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c)
