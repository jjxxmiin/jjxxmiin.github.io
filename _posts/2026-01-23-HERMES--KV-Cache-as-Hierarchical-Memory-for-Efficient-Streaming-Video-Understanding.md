---
layout: post
title: '[2026-01-21] HERMES: KV 캐시를 계층적 메모리로 재설계한 실시간 스트리밍 비디오 이해의 새로운 지평'
date: '2026-01-23'
categories: tech
math: true
summary: 10배 빠른 응답성과 KV 캐시 최적화로 스트리밍 비디오 MLLM의 한계를 돌파한 HERMES 기술 분석
image:
  path: https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2601.14724.png
  alt: Paper Thumbnail
---

# HERMES: KV 캐시를 계층적 메모리로 재설계한 실시간 스트리밍 비디오 이해의 새로운 지평

## 1. 핵심 요약 (Executive Summary)

최근 멀티모달 대규모 언어 모델(MLLM)은 오프라인 비디오 이해 분야에서 비약적인 발전을 이루었으나, 실시간 스트리밍 환경에서의 적용은 여전히 높은 장벽에 가로막혀 있습니다. 기존 방식은 지속적으로 유입되는 비디오 프레임에 대한 실시간 처리, 낮은 GPU 메모리 점유율, 그리고 즉각적인 쿼리 응답 속도라는 세 가지 핵심 요구사항을 동시에 충족하지 못했습니다.

본 분석에서 다룰 **HERMES**는 이러한 한계를 극복하기 위해 제안된 **훈련이 필요 없는(Training-free) 혁신적 아키텍처**입니다. HERMES의 핵심 아이디어는 **KV(Key-Value) 캐시를 단순한 데이터 저장소가 아닌, 비디오 정보를 다중 입도(Multiple Granularities)로 캡슐화하는 '계층적 메모리 프레임워크(Hierarchical Memory Framework)'로 재정의**하는 것입니다. 

HERMES는 기존 SOTA(State-of-the-Art) 모델 대비 **TTFT(Time to First Token)를 10배 단축**시켰으며, 비디오 토큰을 최대 **68%까지 압축**하면서도 스트리밍 벤치마크에서 **최대 11.4%의 성능 향상**을 기록했습니다. 이는 실시간 비디오 보안, 자율 주행, 실시간 스포츠 중계 분석 등 지연 시간에 극도로 민감한 산업군에 즉시 적용 가능한 기술적 도약을 의미합니다.

---

## 2. 연구 배경 및 문제 정의 (Introduction & Problem Statement)

### 2.1. 비디오 MLLM의 병목 현상: '메모리'와 '지연 시간'
현재 대중화된 비디오 이해 모델(예: LLaVA-Video, Video-LLaMA 등)은 대부분 '오프라인' 모드에 최적화되어 있습니다. 즉, 전체 영상을 한 번에 입력받아 처리하는 방식입니다. 하지만 현실 세계의 데이터는 '스트리밍' 형태로 들어옵니다. 스트리밍 비디오 이해를 구현하기 위해 기존 연구들은 다음과 같은 문제에 직면해 왔습니다.

1.  **토큰 폭발(Token Explosion):** 비디오는 초당 수십 프레임으로 구성됩니다. 장시간 스트리밍 시 토큰 수는 기하급수적으로 늘어나며, LLM의 컨텍스트 윈도우(Context Window) 한계를 초과하고 GPU 메모리 고갈을 초래합니다.
2.  **연산 지연(Computational Latency):** 새로운 쿼리가 들어올 때마다 과거의 방대한 비디오 정보를 다시 처리해야 하므로 TTFT가 길어집니다. 이는 실시간 대화형 서비스에서 치명적입니다.
3.  **성능 저하:** 메모리 관리를 위해 단순한 슬라이딩 윈도우(Sliding Window)나 균등 샘플링(Uniform Sampling)을 사용할 경우, 과거의 중요한 맥락(Long-term dependency)을 상실하게 됩니다.

### 2.2. HERMES의 문제 접근 방식
HERMES 팀은 '어텐션 메커니즘(Attention Mechanism)'에 대한 심층적인 조사를 통해, KV 캐시 내의 특정 토큰들이 정보 유지에 결정적인 역할을 한다는 것을 발견했습니다. 이들은 비디오 정보를 계층적으로 관리함으로써, 리소스를 적게 쓰면서도 중요한 맥락을 놓치지 않는 방법을 모색했습니다.

---

## 3. 핵심 기술 및 아키텍처 심층 분석 (Core Methodology)

HERMES의 아키텍처는 크게 세 가지 핵심 기둥으로 구성됩니다.

### 3.1. KV 캐시의 계층적 재구성 (KV Cache as Hierarchical Memory)
HERMES는 KV 캐시를 단순한 선형 큐가 아닌, **계층적 메모리 구조**로 변환합니다. 이는 인간의 기억 시스템(단기 기억과 장기 기억)과 유사한 작동 원리를 가집니다.

*   **로컬 세밀도 캐시(Local Granularity Cache):** 가장 최근에 들어온 프레임들의 상세 정보를 보존합니다. 이는 즉각적인 움직임이나 변화를 감지하는 데 필수적입니다.
*   **글로벌 요약 캐시(Global Summary Cache):** 과거의 프레임들 중 의미론적으로 중요한 정보만을 압축하여 보관합니다. HERMES는 어텐션 맵(Attention Map)의 가중치를 분석하여, 중요도가 낮은 토큰을 적극적으로 폐기(Eviction)하고 핵심 정보를 응축합니다.

### 3.2. 메커니즘 기반 어텐션 조사 (Mechanistic Attention Investigation)
HERMES는 훈련 없이 성능을 내기 위해 기존에 학습된 모델의 어텐션 패턴을 활용합니다. 특정 비디오 토큰이 쿼리에 얼마나 자주 참조되는지를 측정하는 **토큰 중요도 스코어링**을 통해, 어떤 정보를 KV 캐시에 남길지 실시간으로 결정합니다. 이는 정보의 손실을 최소화하면서도 메모리 점유율을 획기적으로 낮추는 비결입니다.

### 3.3. 쿼리 시 보조 연산 제거 (No Auxiliary Computation for Queries)
가장 혁신적인 점은 쿼리가 입력되었을 때 별도의 전처리나 재연산이 필요 없다는 것입니다. 이미 비디오가 스트리밍되는 동안 KV 캐시가 계층적으로 최적화되어 있으므로, LLM은 즉시 쿼리에 대한 응답 생성을 시작할 수 있습니다. 이것이 10배 빠른 TTFT를 가능하게 한 기술적 핵심입니다.

---

## 4. 구현 및 실험 환경 (Implementation Details & Experiment Setup)

HERMES의 효과를 검증하기 위해 연구진은 다양한 벤치마크와 설정에서 실험을 진행했습니다.

*   **베이스라인 모델:** LLaVA 및 기타 최신 비디오 MLLM 아키텍처 활용.
*   **데이터셋:** Streaming-Video 벤치마크 및 다양한 오프라인 비디오 데이터셋(Video-ChatGPT 등).
*   **하드웨어:** NVIDIA A100/H100 GPU 환경에서 스트리밍 시뮬레이션 수행.
*   **최적화 기법:** 별도의 Fine-tuning 없이 기존 가중치를 그대로 사용(Training-free)하여 범용성을 확보했습니다.

---

## 5. 성능 평가 및 비교 (Comparative Analysis)

HERMES는 실험 결과에서 압도적인 효율성과 정확도를 보여주었습니다.

### 5.1. 추론 속도 및 반응성 (Inference Speed)
*   **TTFT(Time to First Token):** 기존 SOTA 대비 **10배 빠른 속도**를 기록했습니다. 이는 사용자가 질문을 던지는 즉시 답변이 시작됨을 의미합니다.
*   **실시간성:** 초당 유입되는 프레임 처리 속도가 모델의 추론 속도를 상회하지 않도록 최적화되어, 끊김 없는 스트리밍 이해가 가능합니다.

### 5.2. 메모리 및 토큰 효율성
*   **토큰 감소:** 균등 샘플링 방식 대비 **최대 68% 적은 토큰**만으로도 유사하거나 더 높은 성능을 보였습니다.
*   **메모리 절감:** KV 캐시 용량을 대폭 줄임으로써, 단일 GPU에서 더 긴 시간의 비디오를 처리할 수 있게 되었습니다.

### 5.3. 정확도 (Accuracy)
*   **스트리밍 벤치마크:** 기존 모델들이 긴 맥락을 잃어버리는 지점에서 HERMES는 계층적 메모리를 통해 성능을 유지, **최대 11.4%의 정확도 향상**을 달성했습니다.

---

## 6. 실제 적용 분야 및 글로벌 파급력 (Real-World Application & Impact)

HERMES의 기술적 성취는 단순히 수치적 우위를 넘어 산업 전반에 막대한 영향을 미칠 것으로 예상됩니다.

1.  **지능형 보안 관제 (Smart Surveillance):** 
    수백 대의 CCTV 카메라가 송출하는 영상을 실시간으로 분석하여 사고, 범죄, 화재 등을 즉각 감지할 수 있습니다. 낮은 GPU 부하 덕분에 인프라 구축 비용을 크게 절감할 수 있습니다.
2.  **자율 주행 및 로보틱스:**
    주변 상황을 실시간으로 '이해'하고 논리적 판단을 내려야 하는 자율 주행 차량이나 로봇에게 HERMES의 빠른 응답 속도와 메모리 효율은 안전과 직결되는 핵심 기술이 될 것입니다.
3.  **라이브 스포츠 및 방송 분석:**
    실시간 경기 상황을 분석하여 하이라이트를 생성하거나, 시청자 질문에 즉각 답변하는 AI 캐스터 서비스 구현이 가능해집니다.
4.  **개인용 AI 비서 (Always-on AI):**
    사용자의 시각적 환경을 상시 모니터링하며 필요한 정보를 제공하는 웨어러블 장치(예: 스마트 글래스)의 온디바이스 AI 구현을 가속화할 것입니다.

---

## 7. 기술적 비평: 한계점 및 비판적 시각 (Discussion & Critique)

Senior Chief AI Scientist로서 본 논문을 비판적으로 분석했을 때, 다음과 같은 고려 사항들이 남아 있습니다.

*   **훈련 부재의 양날의 검 (Training-free Dependency):** 별도의 훈련이 없다는 것은 큰 장점이지만, 동시에 베이스 LLM이 가진 고유한 어텐션 편향(Attention Bias)에 완전히 의존하게 됩니다. 특정 도메인(예: 의료, 복잡한 물리 엔진 영상)에서는 사전 학습된 어텐션 맵이 비효율적일 가능성이 있습니다.
*   **장기 기억의 손실 위험 (Semantic Drift):** 글로벌 요약 캐시가 정보를 압축하는 과정에서, 매우 사소해 보이지만 나중에 결정적인 역할을 하는 '엣지 케이스(Edge Cases)' 정보가 유실될 위험이 있습니다. 계층 구조가 깊어질수록 정보의 희석(Dilution) 문제를 어떻게 해결할 것인지에 대한 추가 연구가 필요합니다.
*   **복잡한 동적 장면에서의 한계:** 빠른 화면 전환이 일어나는 영상에서 '로컬 세밀도 캐시'의 갱신 속도가 물리적 한계에 부딪힐 때, 정확도가 급격히 하락할 가능성이 있습니다.

---

## 8. 결론 및 인사이트 (Conclusion)

HERMES는 **"어떻게 하면 MLLM이 비디오를 '보면서' 동시에 '생각'하게 할 것인가?"**라는 질문에 매우 영리한 해답을 제시했습니다. 기존의 접근 방식이 하드웨어의 힘을 빌려 토큰을 쏟아붓는 방식이었다면, HERMES는 **KV 캐시 아키텍처의 논리적 재구조화**를 통해 소프트웨어 수준의 효율성 극대화를 이루어냈습니다.

특히 10배 빠른 TTFT는 MLLM이 연구실을 넘어 실제 상용 서비스로 나아가기 위한 임계점을 넘은 것으로 평가됩니다. 앞으로 HERMES와 같은 효율적 메모리 관리 기법은 온디바이스 AI와 대규모 실시간 분석 시스템의 표준 아키텍처로 자리 잡을 것입니다.

비디오 데이터를 다루는 엔지니어라면, 이제 모델의 크기를 키우는 것보다 **'메모리를 어떻게 계층화하고 관리할 것인가'**에 더 집중해야 할 때입니다. HERMES는 그 여정의 훌륭한 나침반이 될 것입니다.

[Original Paper Link](https://huggingface.co/papers/2601.14724)